{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-14T15:58:20.875530100Z",
     "start_time": "2025-02-14T15:58:20.697598600Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import configparser\n",
    "import json\n",
    "import tempfile\n",
    "\n",
    "import splitfolders\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Dict, Tuple, List, Union\n",
    "from pathlib import Path\n",
    "from hashlib import sha256\n",
    "\n",
    "from matplotlib import pyplot as plt, image as mpimg\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.src.activations import gelu\n",
    "from keras.src.callbacks import History\n",
    "from numpy import mean, std\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, \\\n",
    "    confusion_matrix\n",
    "\n",
    "\n",
    "DEFAULT_EPOCH = 80"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T15:58:20.892876600Z",
     "start_time": "2025-02-14T15:58:20.877526200Z"
    }
   },
   "id": "de25cd913746ade2",
   "execution_count": 103
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bfa7ab449a75237c"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "62f632cb95a8130f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def snake_to_camel(snake_str):\n",
    "    return \"\".join(x.capitalize() for x in snake_str.lower().split(\"_\"))\n",
    "\n",
    "\n",
    "def camel_to_snake(name):\n",
    "    name = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', name).lower()\n",
    "\n",
    "\n",
    "def get_project_root() -> Path:\n",
    "    return Path(\".\").absolute().parent.parent\n",
    "\n",
    "\n",
    "def reorganize_dict(t):\n",
    "    # Create a new dictionary to store the reorganized data\n",
    "    new_dict = {}\n",
    "\n",
    "    # Loop through the outer dictionary (models)\n",
    "    for model, datasets in t.items():\n",
    "        # Loop through the inner dictionary (datasets)\n",
    "        for dataset, value in datasets.items():\n",
    "            # If the dataset doesn't exist in the new dict, create an entry for it\n",
    "            if dataset not in new_dict:\n",
    "                new_dict[dataset] = {}\n",
    "            # Assign the model and its corresponding value to the new dict under the dataset\n",
    "            new_dict[dataset][model] = copy.deepcopy(value)\n",
    "\n",
    "    return new_dict\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T16:09:49.531717600Z",
     "start_time": "2025-02-14T16:09:49.432010Z"
    }
   },
   "id": "fa82e93b1395527c",
   "execution_count": 118
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we define the datatypes needed to ease the parsing of the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81e3a35fb3d41eff"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MalwareImages:\n",
    "    # A class for loading an image dataset and understanding its class distribution\n",
    "    # and image samples across classes.\n",
    "\n",
    "    # Initialize the dataset loader with the dataset path.\n",
    "    def __init__(self, data_dir: str, n: int):\n",
    "        self.data_directory = data_dir\n",
    "        self.class_distribution = dict()\n",
    "        self.rows = n\n",
    "        self.columns = n\n",
    "\n",
    "    # Computation of the class distribution of the dataset.\n",
    "    def __compute_class_distribution(self):\n",
    "        for malware_type in os.listdir(self.data_directory):\n",
    "            malware_img_dir = os.path.join(self.data_directory, malware_type)\n",
    "            self.class_distribution[malware_type] = len(os.listdir(malware_img_dir))\n",
    "\n",
    "    # Plotting the class distribution.\n",
    "    def plot_class_distribution(self):\n",
    "        self.__compute_class_distribution()\n",
    "\n",
    "        malware_classes = list(self.class_distribution.keys())\n",
    "        malware_class_frequency = list(self.class_distribution.values())\n",
    "        color_palette = sns.color_palette(\"pastel\")\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.barplot(y=malware_classes,\n",
    "                    x=malware_class_frequency,\n",
    "                    palette=color_palette,\n",
    "                    edgecolor=\"black\",\n",
    "                    orient='h')\n",
    "        plt.title(\"Malware Class Distribution\")\n",
    "        plt.xlabel(\"Malware Class Frequency\")\n",
    "        plt.ylabel(\"Malware Type\")\n",
    "\n",
    "    # Insights into samples of different malware images across different classes.\n",
    "    def malware_samples(self):\n",
    "        c = 0\n",
    "        fig, axs = plt.subplots(self.rows, self.columns, figsize=(15, 15))\n",
    "\n",
    "        for malware_type in os.listdir(self.data_directory):\n",
    "            malware_img_dir = os.path.join(self.data_directory, malware_type)\n",
    "            malware_img_sample = random.choice(list(os.listdir(malware_img_dir)))\n",
    "            malware_img_sample_path = os.path.join(malware_img_dir, malware_img_sample)\n",
    "            image = mpimg.imread(malware_img_sample_path)\n",
    "            axs[c // self.columns, c % self.columns].imshow(image, cmap=\"gray\")\n",
    "            axs[c // self.columns, c % self.columns].set_title(malware_type)\n",
    "            c += 1\n",
    "\n",
    "        fig.suptitle(\"Sample for Malware types\")\n",
    "        plt.subplots_adjust(wspace=0.9)\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T16:09:49.590414Z",
     "start_time": "2025-02-14T16:09:49.551437400Z"
    }
   },
   "id": "570371a109faec83",
   "execution_count": 119
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we define the Image Processor. The Image processor class will be in charge of pre-processing Malware byteplots to augment the dataset whenever needed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd71d7227f65ac6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# A class to preprocess the malware images to make it usable for training neural networks.\n",
    "class ImageProcessor:\n",
    "\n",
    "    # Initialization of the image pre-processor with required file locations.\n",
    "    def __init__(self, train_dir: str, test_dir: str, val_dir: str, size, colormode: str) -> None:\n",
    "        self.train_gen = None\n",
    "        self.test_gen = None\n",
    "        self.val_gen = None\n",
    "        self.colormode = colormode\n",
    "        self.training_data_directory = train_dir\n",
    "        self.testing_data_directory = test_dir\n",
    "        self.validation_data_directory = val_dir\n",
    "        self.size = size\n",
    "        self.batch_size = 32\n",
    "        self.seed = 42\n",
    "        self.class_mode = \"categorical\"\n",
    "\n",
    "    # Creating generators based on the preprocessing requirements of the CNN architecture.\n",
    "    def create_generators(self):\n",
    "        self.train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rescale=1. / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True,\n",
    "        )\n",
    "\n",
    "        self.test_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rescale=1. / 255\n",
    "        )\n",
    "\n",
    "        self.val_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rescale=1. / 255\n",
    "        )\n",
    "\n",
    "    # Reading the images from the respective directories.\n",
    "    def get_images(self):\n",
    "        train_images = self.train_gen.flow_from_directory(\n",
    "            directory=self.training_data_directory,\n",
    "            target_size=self.size,\n",
    "            color_mode=self.colormode,\n",
    "            class_mode=self.class_mode,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            seed=self.seed,\n",
    "            subset='training',\n",
    "        )\n",
    "\n",
    "        val_images = self.val_gen.flow_from_directory(\n",
    "            directory=self.validation_data_directory,\n",
    "            target_size=self.size,\n",
    "            classes=sorted([i for i in os.listdir(self.training_data_directory)]),\n",
    "            color_mode=self.colormode,\n",
    "            class_mode=self.class_mode,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            seed=self.seed\n",
    "        )\n",
    "\n",
    "        test_images = self.test_gen.flow_from_directory(\n",
    "            directory=self.testing_data_directory,\n",
    "            target_size=self.size,\n",
    "            color_mode=self.colormode,\n",
    "            class_mode=self.class_mode,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            seed=self.seed\n",
    "        )\n",
    "\n",
    "        return train_images, val_images, test_images\n",
    "\n",
    "    @staticmethod\n",
    "    def generator_to_numpy(generator):\n",
    "        \"\"\"\n",
    "        Convert a Keras image generator to numpy arrays of data and labels.\n",
    "\n",
    "        Args:\n",
    "            generator: Keras ImageDataGenerator flow instance.\n",
    "\n",
    "        Returns:\n",
    "            X (np.ndarray): Flattened image data.\n",
    "            y (np.ndarray): One-hot encoded labels.\n",
    "        \"\"\"\n",
    "        X, y = [], []\n",
    "        for batch_x, batch_y in generator:\n",
    "            X.append(batch_x)\n",
    "            y.append(batch_y)\n",
    "            if len(X) * generator.batch_size >= generator.n:\n",
    "                break\n",
    "        X = np.vstack(X)  # Combine all batches into one array\n",
    "        y = np.vstack(y)  # Combine all labels into one array\n",
    "\n",
    "        y = np.argmax(y, axis=1)  # Convert one-hot labels to class indices\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def get_image_flattened(self):\n",
    "        train_images, val_images, test_images = self.get_images()\n",
    "\n",
    "        # Convert train, validation, and test data to numpy arrays\n",
    "        x_train, y_train = ImageProcessor.generator_to_numpy(train_images)\n",
    "        x_val, y_val = ImageProcessor.generator_to_numpy(val_images)\n",
    "        x_test, y_test = ImageProcessor.generator_to_numpy(test_images)\n",
    "\n",
    "        # Flatten the image data for classical models\n",
    "        x_train = x_train.reshape(x_train.shape[0], -1)  # Flatten each image\n",
    "        x_val = x_val.reshape(x_val.shape[0], -1)  # Flatten each image\n",
    "        x_test = x_test.reshape(x_test.shape[0], -1)  # Flatten each image\n",
    "\n",
    "        # We also scale the data\n",
    "        scaler = StandardScaler()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_val = scaler.transform(x_val)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        return x_train, y_train, x_val, y_val, x_test, y_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T16:09:49.989482Z",
     "start_time": "2025-02-14T16:09:49.951779200Z"
    }
   },
   "id": "205fd6c5bd501448",
   "execution_count": 120
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, the Dataset loader, which will be used to load the images from the filesystem, provide an API to split them into train/test/validation, etc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9877dac2eaccaa4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DatasetLoader:\n",
    "    def __init__(self):\n",
    "        # Define data directories using pathlib for OS-independent paths\n",
    "        self.project_root = get_project_root().absolute()\n",
    "        print(f\"(*) Using project root: {self.project_root}\")\n",
    "        config_folder = self.project_root.joinpath(\"mcmls\", \"config\")\n",
    "        cf = config_folder.joinpath(\"config.ini\")\n",
    "        self.config = configparser.ConfigParser(allow_no_value=True, interpolation=configparser.ExtendedInterpolation())\n",
    "        self.config.read(str(cf))\n",
    "        self.project_root = self.project_root.joinpath(\"vitaminc\")\n",
    "        dataset_cf = self.project_root.joinpath(self.config.get(\"DATASET\", \"config\")).resolve()\n",
    "        self.dataset_config = {}\n",
    "        self.training_datasets: Dict[str, MalwareImages] = dict()\n",
    "        # This seed is l33t\n",
    "        self.seed = 1337\n",
    "        with open(str(dataset_cf), \"r\") as _in:\n",
    "            datasets = json.load(_in)\n",
    "            for dataset in datasets.get(\"datasets\"):\n",
    "                self.dataset_config[dataset.get(\"name\")] = dataset\n",
    "\n",
    "        self.__base_data_directory = self.project_root.joinpath(\"data\")\n",
    "        self.__base_split_directory = self.project_root.joinpath(\"split\")\n",
    "\n",
    "        # Ensure existence\n",
    "        self.__base_data_directory.mkdir(exist_ok=True)\n",
    "        self.__base_split_directory.mkdir(exist_ok=True)\n",
    "\n",
    "    def list_datasets(self) -> List[str]:\n",
    "        if not self.dataset_config:\n",
    "            return []\n",
    "        return [x for x in self.dataset_config.keys()]\n",
    "\n",
    "    def get_dataset_directory(self, dataset_name: str) -> Path:\n",
    "        # Dataset directories\n",
    "        if dataset_name not in self.list_datasets():\n",
    "            raise ValueError(f\"Dataset {dataset_name} not supported\")\n",
    "        return self.__base_data_directory.joinpath(f\"{dataset_name}_dataset\")\n",
    "\n",
    "    def get_dataset_image_size(self, dataset_name: str) -> Tuple[int, int]:\n",
    "        if dataset_name not in self.list_datasets():\n",
    "            raise ValueError(f\"Dataset {dataset_name} not supported\")\n",
    "        w = int(self.dataset_config.get(dataset_name, {}).get(\"image_size\").get(\"w\"))\n",
    "        h = int(self.dataset_config.get(dataset_name, {}).get(\"image_size\").get(\"h\"))\n",
    "        return w, h\n",
    "\n",
    "    def get_dataset_image_colormode(self, dataset_name: str) -> str:\n",
    "        if dataset_name not in self.list_datasets():\n",
    "            raise ValueError(f\"Dataset {dataset_name} not supported\")\n",
    "        mode = self.dataset_config.get(dataset_name, {}).get(\"colormode\")\n",
    "        if mode not in [\"rgb\", \"grayscale\"]:\n",
    "            return \"rgb\"\n",
    "        return mode\n",
    "\n",
    "    def get_dataset_class_number(self, dataset_name: str) -> int:\n",
    "        if dataset_name not in self.list_datasets():\n",
    "            raise ValueError(f\"Dataset {dataset_name} not supported\")\n",
    "        classes = self.dataset_config.get(dataset_name, {}).get(\"classes\")\n",
    "        return int(classes)\n",
    "\n",
    "    def get_dataset_options(self, dataset_name: str) -> dict:\n",
    "        if dataset_name not in self.list_datasets():\n",
    "            raise ValueError(f\"Dataset {dataset_name} not supported\")\n",
    "        options = self.dataset_config.get(dataset_name, {}).get(\"options\")\n",
    "        return options\n",
    "\n",
    "    def get_split_directory(self, dataset_name: str) -> Path:\n",
    "        # Split Dataset directories\n",
    "        if dataset_name not in self.list_datasets():\n",
    "            raise ValueError(f\"Dataset {dataset_name} not supported\")\n",
    "        return self.__base_split_directory.joinpath(f\"{dataset_name}_dataset\")\n",
    "\n",
    "    # Splitting the dataset into training and testing subsets proportionally.\n",
    "    def __split_dataset(self, src: str, dst: str, train_ratio: float, test_ratio: float):\n",
    "        splitfolders.ratio(input=src,\n",
    "                           output=dst,\n",
    "                           seed=self.seed,\n",
    "                           ratio=(train_ratio, 0, test_ratio),\n",
    "                           group_prefix=None,\n",
    "                           move=False)\n",
    "\n",
    "    def split_dataset(self, dataset_name: str) -> bool:\n",
    "        if dataset_name not in self.list_datasets():\n",
    "            raise ValueError(f\"Dataset {dataset_name} not supported\")\n",
    "        train_d = self.get_dataset_directory(dataset_name).joinpath(\"train\")\n",
    "        new_train_test_d = self.get_split_directory(dataset_name)\n",
    "        # Ensure the split doesn't exist yet\n",
    "        if not new_train_test_d.is_dir():\n",
    "            self.__split_dataset(str(train_d), str(new_train_test_d), 0.8, 0.2)\n",
    "\n",
    "        # Cheating: just check for the directories to exist\n",
    "        return self.get_training_data_dir(dataset_name).is_dir() and self.get_testing_data_dir(dataset_name).is_dir()\n",
    "\n",
    "    def get_training_data_dir(self, dataset_name: str, split: bool = True) -> Path:\n",
    "        if split:\n",
    "            return self.get_split_directory(dataset_name).joinpath(\"train\")\n",
    "        return self.get_dataset_directory(dataset_name).joinpath(\"train\")\n",
    "\n",
    "    def get_validation_data_dir(self, dataset_name: str) -> Path:\n",
    "        return self.get_dataset_directory(dataset_name).joinpath(\"val\")\n",
    "\n",
    "    def get_testing_data_dir(self, dataset_name: str) -> Path:\n",
    "        return self.get_split_directory(dataset_name).joinpath(\"test\")\n",
    "\n",
    "    def split_all_dataset(self) -> bool:\n",
    "        success = []\n",
    "        for dataset_name in self.list_datasets():\n",
    "            print(f\"(*) Splitting dataset {dataset_name} in Train / Test / Validate\")\n",
    "            success.append(self.split_dataset(dataset_name))\n",
    "        return all(success)\n",
    "\n",
    "    def load_dataset(self, dataset_name: str, split: bool):\n",
    "        if dataset_name not in self.list_datasets():\n",
    "            raise ValueError(f\"Dataset {dataset_name} not supported\")\n",
    "        self.training_datasets[dataset_name] = MalwareImages(\n",
    "            data_dir=str(self.get_training_data_dir(dataset_name, split=split)),\n",
    "            n=int(self.dataset_config.get(dataset_name, {}).get(\"d\"))\n",
    "        )\n",
    "\n",
    "    def load_datasets(self, split: bool):\n",
    "        for dataset_name in self.list_datasets():\n",
    "            self.load_dataset(dataset_name, split=split)\n",
    "\n",
    "    def plot_datasets(self):\n",
    "        for dataset_name in self.list_datasets():\n",
    "            self.plot_dataset(dataset_name)\n",
    "\n",
    "    def plot_dataset(self, dataset_name: str):\n",
    "        if dataset_name not in self.list_datasets():\n",
    "            raise ValueError(f\"Dataset {dataset_name} not supported\")\n",
    "        dataset = self.training_datasets.get(dataset_name)\n",
    "        if dataset is not None:\n",
    "            dataset.plot_class_distribution()\n",
    "            dataset.malware_samples()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T16:09:50.273208Z",
     "start_time": "2025-02-14T16:09:50.251696300Z"
    }
   },
   "id": "109b65f67c5aa76f",
   "execution_count": 121
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, to simplify the creation of the models that we want to compare, we provide an abstract interface"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cbac606ffbac14f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class IModel(ABC):\n",
    "\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        self.checkpoint_filepath = tempfile.NamedTemporaryFile(delete=False, suffix=\".weights.h5\").name\n",
    "        self.kwargs = kwargs\n",
    "        self.train = self.kwargs.pop(\"training\", None)  # Remove DirectoryIterator cause it can't be serialized\n",
    "        self.val = kwargs.get(\"validation\")\n",
    "        self.history = None\n",
    "        self.number_of_classes = kwargs.get(\"number_of_classes\")\n",
    "        self.regularize = kwargs.get(\"regularize\", False)\n",
    "        self.patience = kwargs.get(\"patience\", 10)\n",
    "        self.num_epoch = kwargs.get(\"num_epoch\", DEFAULT_EPOCH)\n",
    "        self.learning_rate = kwargs.get(\"learning_rate\", 0.001)\n",
    "        self.weight_decay = kwargs.get(\"weight_decay\", 0.0001)\n",
    "        self.activation = kwargs.get(\"activation\", gelu)\n",
    "        self.input_shape = kwargs.get(\"input_shape\")\n",
    "        self.batch_size = 32\n",
    "        self.callbacks = []\n",
    "\n",
    "        # Because we all know the ultimate answer is 42\n",
    "        self.random_state = 42\n",
    "\n",
    "        # Params really needed in classic learning\n",
    "        self.solver = kwargs.get(\"solver\")\n",
    "        self.n_jobs = kwargs.get(\"n_jobs\", -1)\n",
    "        self.multi_class = kwargs.get(\"multi_class\")\n",
    "        self.cv = kwargs.get(\"cv\", RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1))\n",
    "\n",
    "        # Inner model supported by scikit\n",
    "        self.model = None\n",
    "\n",
    "    def load_kwargs(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "        self.train = kwargs.get(\"training\")\n",
    "        self.val = kwargs.get(\"validation\")\n",
    "        self.number_of_classes = kwargs.get(\"number_of_classes\")\n",
    "        self.regularize = kwargs.get(\"regularize\", False)\n",
    "        self.patience = kwargs.get(\"patience\", 10)\n",
    "        self.num_epoch = kwargs.get(\"num_epoch\", DEFAULT_EPOCH)\n",
    "        self.learning_rate = kwargs.get(\"learning_rate\", 0.001)\n",
    "        self.weight_decay = kwargs.get(\"weight_decay\", 0.0001)\n",
    "        self.activation = kwargs.get(\"activation\", gelu)\n",
    "        self.input_shape = kwargs.get(\"input_shape\")\n",
    "\n",
    "    def enable_checkpoint(self):\n",
    "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            self.checkpoint_filepath,\n",
    "            monitor=\"val_accuracy\",\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True,\n",
    "        )\n",
    "        self.callbacks.append(checkpoint_callback)\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        # evaluate the model and collect the scores\n",
    "        n_scores = cross_val_score(self.model, X, y, scoring='accuracy', cv=self.cv, n_jobs=self.n_jobs)\n",
    "        # report the model performance\n",
    "        print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "\n",
    "    def search_best_cv(self, X, y, solvers: list = None):\n",
    "        if solvers is None or len(solvers) == 0:\n",
    "            return\n",
    "        grid = dict()\n",
    "        grid['solver'] = solvers\n",
    "        # define search\n",
    "        search = GridSearchCV(self.model, grid, scoring='accuracy', cv=self.cv, n_jobs=self.n_jobs)\n",
    "        # perform the search\n",
    "        results = search.fit(X, y)\n",
    "        # summarize\n",
    "        print('Mean Accuracy: %.3f' % results.best_score_)\n",
    "        print('Config: %s' % results.best_params_)\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_model(self, preprocess=True):\n",
    "        pass\n",
    "\n",
    "    # Training the model with Early Stopping Criterion\n",
    "    # on Validation Loss.\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def smote(self, x_train, y_train) -> tuple:\n",
    "        smote = SMOTE(random_state=self.random_state)\n",
    "        x_train_balanced, y_train_balanced = smote.fit_resample(x_train, y_train)\n",
    "        return x_train_balanced, y_train_balanced\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def save_inner_model(self, path: Path):\n",
    "        self.model.save(str(path))\n",
    "\n",
    "    def load_inner_model(self, path: Path):\n",
    "        self.model = keras.models.load_model(str(path))\n",
    "\n",
    "    def save_parameters(self, path: Path):\n",
    "        with open(str(path), \"w\") as f:\n",
    "            json.dump(self.kwargs.__dict__, f)\n",
    "\n",
    "    def load_parameters(self, path: Path):\n",
    "        with open(str(path), \"r\") as f:\n",
    "            kwargs = json.load(f)\n",
    "        self.load_kwargs(**kwargs)\n",
    "\n",
    "    def save_history(self, path: Path):\n",
    "        with open(str(path), \"w\") as f:\n",
    "            json.dump(self.history.history, f)\n",
    "\n",
    "    def load_history(self, path: Path):\n",
    "        with open(str(path), \"r\") as f:\n",
    "            self.history = History()\n",
    "            self.history.history = json.load(f)\n",
    "\n",
    "    # This function should be used to identify specific constructions of the ViT\n",
    "    def hashed_params(self):\n",
    "        return sha256(json.dumps(self.kwargs, sort_keys=True).encode('utf8')).hexdigest()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T16:09:50.799805700Z",
     "start_time": "2025-02-14T16:09:50.772678800Z"
    }
   },
   "id": "804bea6841fda6ba",
   "execution_count": 122
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, a factory to instantiate a specific model by name"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "493e811e22356277"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "class ModelFactory:\n",
    "    @staticmethod\n",
    "    def from_name(name: str, **kwargs) -> Union[IModel, None]:\n",
    "        try:\n",
    "            _class_name = name\n",
    "            _class = eval(f\"{_class_name}Model\")\n",
    "            return _class(**kwargs)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def list_all():\n",
    "        models = [\n",
    "            \"lr\", \"lda\", \"qda\", \"dtc\", \"svm\"\n",
    "        ]\n",
    "        return [snake_to_camel(m) for m in models]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T16:09:51.250714200Z",
     "start_time": "2025-02-14T16:09:51.237025500Z"
    }
   },
   "id": "6aabdbde4bc53dcf",
   "execution_count": 123
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "38977396e39aff3c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally we start implementing the various models to compare. THe first is a standard liner regressor."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b632e78187874e3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "class LrModel(IModel):\n",
    "    def __init__(self):\n",
    "        kwargs = {\n",
    "            \"multi_class\": \"multinomial\",\n",
    "            \"solver\": \"lbfgs\"\n",
    "        }\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = \"Logistic Regression\"\n",
    "\n",
    "    def create_model(self, preprocess=False):\n",
    "        self.model = LogisticRegression(multi_class=self.multi_class, solver=self.solver)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T16:09:51.697222500Z",
     "start_time": "2025-02-14T16:09:51.684034700Z"
    }
   },
   "id": "f6840db9a3632205",
   "execution_count": 124
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "84d8663a51339aec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "class LdaModel(IModel):\n",
    "    def __init__(self):\n",
    "        kwargs = {\n",
    "            \"multi_class\": \"multinomial\",\n",
    "            \"solver\": \"svd\"\n",
    "        }\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = \"Linear Discriminant Analysis\"\n",
    "\n",
    "    def create_model(self, preprocess=False):\n",
    "        self.model = LinearDiscriminantAnalysis(solver=self.solver)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T16:09:52.009470300Z",
     "start_time": "2025-02-14T16:09:51.997445500Z"
    }
   },
   "id": "3289e424a271b9a2",
   "execution_count": 125
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ce16cbadc561fd9a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "class QdaModel(IModel):\n",
    "    def __init__(self):\n",
    "        kwargs = {\n",
    "        }\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = \"Quadratic Discriminant Analysis\"\n",
    "\n",
    "    def create_model(self, preprocess=False):\n",
    "        self.model = QuadraticDiscriminantAnalysis()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T16:09:52.487894300Z",
     "start_time": "2025-02-14T16:09:52.476279800Z"
    }
   },
   "id": "652ca720cfe24671",
   "execution_count": 126
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a26417f53435596a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "class DtcModel(IModel):\n",
    "    def __init__(self):\n",
    "        kwargs = {\n",
    "            \"criterion\": \"gini\",\n",
    "            \"splitter\": \"best\"\n",
    "        }\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = \"Decision Tree Classifier\"\n",
    "\n",
    "    def create_model(self, preprocess=False):\n",
    "        self.model = DecisionTreeClassifier(**self.kwargs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T16:09:52.850356600Z",
     "start_time": "2025-02-14T16:09:52.837710600Z"
    }
   },
   "id": "87ade0309ab87d1",
   "execution_count": 127
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "37a9ca82f96aaffa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "class SvcModel(IModel):\n",
    "    def __init__(self):\n",
    "        kwargs = {\n",
    "            \"kernel\": \"rbf\",\n",
    "            \"C\": 1.0,\n",
    "            \"gamma\": \"scale\"\n",
    "        }\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = \"Support Vector Classifier\"\n",
    "\n",
    "    def create_model(self, preprocess=False):\n",
    "        self.model = SVC(**self.kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T16:09:53.176460300Z",
     "start_time": "2025-02-14T16:09:53.164888600Z"
    }
   },
   "id": "ceab4e5702741e53",
   "execution_count": 128
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9eef0958b493d265"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, finally, we can create the main class, MCMLS  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d42c123d215ac059"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class McMls:\n",
    "    def __init__(self, results_dir: str):\n",
    "        \"\"\"\n",
    "        Initialize the pipeline.\n",
    "\n",
    "        Args:\n",
    "            results_dir: Path to store results.\n",
    "        \"\"\"\n",
    "        self.loader: DatasetLoader = DatasetLoader()\n",
    "        self.results_directory = Path(self.loader.config.get(\"GLOBAL\", \"results\"))\n",
    "        self.results_directory.mkdir(exist_ok=True)\n",
    "        self.test_data = {dataset: {} for dataset in self.loader.list_datasets()}\n",
    "        self.mc = None\n",
    "        self.dmc = None\n",
    "        self.__supported_models: List[str] = ModelFactory.list_all()\n",
    "\n",
    "        self.results_dir = Path(results_dir)\n",
    "        self.results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.results = {dataset: {} for dataset in self.loader.list_datasets()}\n",
    "\n",
    "    def list_models(self) -> List[str]:\n",
    "        \"\"\"Return a list of supported models.\"\"\"\n",
    "        return list(self.__supported_models)\n",
    "\n",
    "    def preprocess_dataset(self, dataset_name: str):\n",
    "        \"\"\"\n",
    "        Preprocess a dataset using the ImageProcessor class.\n",
    "\n",
    "        Args:\n",
    "            dataset_name: Name of the dataset to preprocess.\n",
    "\n",
    "        Returns:\n",
    "            Tuple of flattened train, validation, and test data.\n",
    "        \"\"\"\n",
    "        image_flat_size = self.loader.get_dataset_image_size(dataset_name)\n",
    "        color_mode = self.loader.get_dataset_image_colormode(dataset_name)\n",
    "\n",
    "        # Preprocessing the images.\n",
    "        preprocessor = ImageProcessor(\n",
    "            str(self.loader.get_training_data_dir(dataset_name, split=True)),\n",
    "            str(self.loader.get_testing_data_dir(dataset_name)),\n",
    "            str(self.loader.get_validation_data_dir(dataset_name)),\n",
    "            image_flat_size,\n",
    "            color_mode\n",
    "        )\n",
    "        preprocessor.create_generators()\n",
    "\n",
    "        # Get flattened data\n",
    "        return preprocessor.get_image_flattened()\n",
    "\n",
    "    def train_and_evaluate(self, model_name: str, dataset_name: str):\n",
    "        \"\"\"\n",
    "        Train and evaluate a model on the given dataset.\n",
    "\n",
    "        Args:\n",
    "            model_name: Name of the model to train.\n",
    "            dataset_name: Name of the dataset to use.\n",
    "        \"\"\"\n",
    "        # Preprocess dataset\n",
    "        x_train, y_train, x_val, y_val, x_test, y_test = self.preprocess_dataset(dataset_name)\n",
    "\n",
    "        # Initialize and train the model\n",
    "        model = ModelFactory.from_name(model_name)\n",
    "        model.create_model()\n",
    "\n",
    "        # We try to balance it\n",
    "        x_train, y_train = model.smote(x_train, y_train)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        val_predictions = model.predict(x_val)\n",
    "        test_predictions = model.predict(x_test)\n",
    "\n",
    "        # Compute validation metrics\n",
    "        val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "        val_precision = precision_score(y_val, val_predictions, average=\"weighted\", zero_division=1)\n",
    "        val_recall = recall_score(y_val, val_predictions, average=\"weighted\", zero_division=1)\n",
    "        val_f1 = f1_score(y_val, val_predictions, average=\"weighted\", zero_division=1)\n",
    "\n",
    "        # Compute test metrics\n",
    "        test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "        test_precision = precision_score(y_test, test_predictions, average=\"weighted\", zero_division=1)\n",
    "        test_recall = recall_score(y_test, test_predictions, average=\"weighted\", zero_division=1)\n",
    "        test_f1 = f1_score(y_test, test_predictions, average=\"weighted\", zero_division=1)\n",
    "\n",
    "        # Classification report\n",
    "        report = classification_report(y_test, test_predictions, output_dict=True, zero_division=1)\n",
    "\n",
    "        # Confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "        # Save results\n",
    "        self.results[dataset_name][model_name] = {\n",
    "            \"validation_metrics\": {\n",
    "                \"accuracy\": val_accuracy,\n",
    "                \"precision\": val_precision,\n",
    "                \"recall\": val_recall,\n",
    "                \"f1_score\": val_f1,\n",
    "            },\n",
    "            \"test_metrics\": {\n",
    "                \"accuracy\": test_accuracy,\n",
    "                \"precision\": test_precision,\n",
    "                \"recall\": test_recall,\n",
    "                \"f1_score\": test_f1,\n",
    "            },\n",
    "            \"classification_report\": report,\n",
    "            \"confusion_matrix\": conf_matrix.tolist(),  # Convert to list for JSON serialization\n",
    "        }\n",
    "\n",
    "    def evaluate_all_models(self):\n",
    "        \"\"\"Evaluate all models on all datasets.\"\"\"\n",
    "        for dataset in self.loader.list_datasets():\n",
    "            for model_name in self.list_models():\n",
    "                try:\n",
    "                    print(f\"Training {model_name} on {dataset}...\")\n",
    "                    self.train_and_evaluate(model_name, dataset)\n",
    "                except Exception as e:\n",
    "                    print(f\"Exception occurred training {model_name} on {dataset}: {e}\")\n",
    "\n",
    "    def save_results(self):\n",
    "        \"\"\"Save all evaluation results as JSON.\"\"\"\n",
    "        for dataset, dataset_results in self.results.items():\n",
    "            dataset_dir = self.results_dir.joinpath(dataset)\n",
    "            dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            for model_name, model_results in dataset_results.items():\n",
    "                model_path = dataset_dir.joinpath(f\"{model_name}_results.json\")\n",
    "                with open(model_path, \"w\") as f:\n",
    "                    json.dump(model_results, f)\n",
    "\n",
    "    def load_results(self):\n",
    "        \"\"\"Load previously saved results into memory.\"\"\"\n",
    "        for dataset in self.loader.list_datasets():\n",
    "            dataset_dir = self.results_dir.joinpath(dataset)\n",
    "            if not dataset_dir.is_dir():\n",
    "                continue\n",
    "\n",
    "            for model_file in dataset_dir.glob(\"*_results.json\"):\n",
    "                model_name = model_file.stem.replace(\"_results\", \"\")\n",
    "                with open(model_file, \"r\") as f:\n",
    "                    self.results[dataset][model_name] = json.load(f)\n",
    "\n",
    "    def summarize_results(self):\n",
    "        \"\"\"\n",
    "        Summarize and visualize the results collected in self.results.\n",
    "\n",
    "        Produces:\n",
    "        - A summary table of key metrics (accuracy, precision, recall, F1-score).\n",
    "        - A bar plot comparing test accuracy across models and datasets.\n",
    "        - A heatmap for F1-scores across models and datasets.\n",
    "        \"\"\"\n",
    "        # Collect data into a DataFrame for easy visualization\n",
    "        summary_data = []\n",
    "        for dataset_name, models in self.results.items():\n",
    "            for model_name, metrics in models.items():\n",
    "                test_metrics = metrics[\"test_metrics\"]\n",
    "                summary_data.append({\n",
    "                    \"Dataset\": dataset_name,\n",
    "                    \"Model\": model_name,\n",
    "                    \"Accuracy\": test_metrics[\"accuracy\"],\n",
    "                    \"Precision\": test_metrics[\"precision\"],\n",
    "                    \"Recall\": test_metrics[\"recall\"],\n",
    "                    \"F1-Score\": test_metrics[\"f1_score\"]\n",
    "                })\n",
    "\n",
    "        # Create a DataFrame for easier manipulation\n",
    "        df = pd.DataFrame(summary_data)\n",
    "\n",
    "        # Display the summary table\n",
    "        print(\"Summary of Results:\")\n",
    "        print(df)\n",
    "\n",
    "        # Bar plot for accuracy comparison\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(data=df, x=\"Dataset\", y=\"Accuracy\", hue=\"Model\", ci=None)\n",
    "        plt.title(\"Test Accuracy Comparison\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"Dataset\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Heatmap for F1-Scores\n",
    "        f1_pivot = df.pivot(\"Model\", \"Dataset\", \"F1-Score\")\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(f1_pivot, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "        plt.title(\"F1-Score Heatmap\")\n",
    "        plt.ylabel(\"Model\")\n",
    "        plt.xlabel(\"Dataset\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confusion_matrix_from_results(self, dataset_name: str, model_name: str, class_names: List[str]):\n",
    "        \"\"\"\n",
    "        Plot the confusion matrix for a specific dataset and model using self.results.\n",
    "\n",
    "        Args:\n",
    "            dataset_name (str): Name of the dataset.\n",
    "            model_name (str): Name of the model.\n",
    "            class_names (List[str]): List of class names.\n",
    "        \"\"\"\n",
    "        if dataset_name not in self.results:\n",
    "            print(f\"Dataset '{dataset_name}' not found in results.\")\n",
    "            return\n",
    "        if model_name not in self.results[dataset_name]:\n",
    "            print(f\"Model '{model_name}' not found for dataset '{dataset_name}'.\")\n",
    "            return\n",
    "\n",
    "        # Retrieve confusion matrix\n",
    "        conf_matrix = self.results[dataset_name][model_name][\"confusion_matrix\"]\n",
    "\n",
    "        # Plot using seaborn\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.xlabel(\"Predicted Labels\")\n",
    "        plt.ylabel(\"True Labels\")\n",
    "        plt.title(f\"Confusion Matrix: {model_name} on {dataset_name}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def compare_models(self, dataset: str):\n",
    "        \"\"\"\n",
    "        Compare performance of all models for a given dataset.\n",
    "\n",
    "        Args:\n",
    "            dataset: Name of the dataset.\n",
    "        \"\"\"\n",
    "        if dataset not in self.results:\n",
    "            print(f\"No results for dataset: {dataset}\")\n",
    "            return\n",
    "\n",
    "        print(f\"Comparison for {dataset}:\\n\")\n",
    "        for model_name, model_results in self.results[dataset].items():\n",
    "            print(f\"Model: {model_name}\")\n",
    "            print(f\"Validation Accuracy: {model_results['validation_metrics']['accuracy']:.2f}\")\n",
    "            print(f\"Test Accuracy: {model_results['test_metrics']['accuracy']:.2f}\\n\")\n",
    "\n",
    "    def compare_datasets(self, model_name: str):\n",
    "        \"\"\"\n",
    "        Compare performance of a specific model across datasets.\n",
    "\n",
    "        Args:\n",
    "            model_name: Name of the model.\n",
    "        \"\"\"\n",
    "        if model_name not in self.list_models():\n",
    "            print(f\"No such model: {model_name}\")\n",
    "            return\n",
    "\n",
    "        print(f\"Comparison for model: {model_name}\\n\")\n",
    "        for dataset, dataset_results in self.results.items():\n",
    "            if model_name not in dataset_results:\n",
    "                print(f\"Model not evaluated on dataset: {dataset}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Dataset: {dataset}\")\n",
    "            print(f\"Validation Accuracy: {dataset_results[model_name]['validation_metrics']['accuracy']:.2f}\")\n",
    "            print(f\"Test Accuracy: {dataset_results[model_name]['test_metrics']['accuracy']:.2f}\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T16:09:53.827662800Z",
     "start_time": "2025-02-14T16:09:53.815482Z"
    }
   },
   "id": "9eca5a99d81c2cce",
   "execution_count": 129
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that the classes are all in, we can run our evaluation. Firstly, we initialize the datasets and the Malware classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26f99cce3c9033f4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) Using project root: C:\\Dev\n",
      "(*) Using project root: C:\\Dev\n"
     ]
    }
   ],
   "source": [
    "# Initialize the pipeline with the DataLoader and ImageProcessor\n",
    "loader = DatasetLoader()\n",
    "pipeline = McMls(results_dir=\"results\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T16:09:54.727109Z",
     "start_time": "2025-02-14T16:09:54.717221100Z"
    }
   },
   "id": "dee9b7d917a50e0d",
   "execution_count": 130
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we train all the models within the classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7910d7626a69c93"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Lr on malimg...\n",
      "Found 6711 images belonging to 25 classes.\n",
      "Found 910 images belonging to 25 classes.\n",
      "Found 1693 images belonging to 25 classes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[131], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Train and evaluate all models\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mpipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate_all_models\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[129], line 117\u001B[0m, in \u001B[0;36mMcMls.evaluate_all_models\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_and_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mException occurred training \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[129], line 61\u001B[0m, in \u001B[0;36mMcMls.train_and_evaluate\u001B[1;34m(self, model_name, dataset_name)\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;124;03mTrain and evaluate a model on the given dataset.\u001B[39;00m\n\u001B[0;32m     55\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;124;03m    dataset_name: Name of the dataset to use.\u001B[39;00m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;66;03m# Preprocess dataset\u001B[39;00m\n\u001B[1;32m---> 61\u001B[0m x_train, y_train, x_val, y_val, x_test, y_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocess_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;66;03m# Initialize and train the model\u001B[39;00m\n\u001B[0;32m     64\u001B[0m model \u001B[38;5;241m=\u001B[39m ModelFactory\u001B[38;5;241m.\u001B[39mfrom_name(model_name)\n",
      "Cell \u001B[1;32mIn[129], line 50\u001B[0m, in \u001B[0;36mMcMls.preprocess_dataset\u001B[1;34m(self, dataset_name)\u001B[0m\n\u001B[0;32m     47\u001B[0m preprocessor\u001B[38;5;241m.\u001B[39mcreate_generators()\n\u001B[0;32m     49\u001B[0m \u001B[38;5;66;03m# Get flattened data\u001B[39;00m\n\u001B[1;32m---> 50\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpreprocessor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_image_flattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[120], line 97\u001B[0m, in \u001B[0;36mImageProcessor.get_image_flattened\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     94\u001B[0m train_images, val_images, test_images \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_images()\n\u001B[0;32m     96\u001B[0m \u001B[38;5;66;03m# Convert train, validation, and test data to numpy arrays\u001B[39;00m\n\u001B[1;32m---> 97\u001B[0m x_train, y_train \u001B[38;5;241m=\u001B[39m \u001B[43mImageProcessor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerator_to_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_images\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     98\u001B[0m x_val, y_val \u001B[38;5;241m=\u001B[39m ImageProcessor\u001B[38;5;241m.\u001B[39mgenerator_to_numpy(val_images)\n\u001B[0;32m     99\u001B[0m x_test, y_test \u001B[38;5;241m=\u001B[39m ImageProcessor\u001B[38;5;241m.\u001B[39mgenerator_to_numpy(test_images)\n",
      "Cell \u001B[1;32mIn[120], line 81\u001B[0m, in \u001B[0;36mImageProcessor.generator_to_numpy\u001B[1;34m(generator)\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;124;03mConvert a Keras image generator to numpy arrays of data and labels.\u001B[39;00m\n\u001B[0;32m     72\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;124;03m    y (np.ndarray): One-hot encoded labels.\u001B[39;00m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     80\u001B[0m X, y \u001B[38;5;241m=\u001B[39m [], []\n\u001B[1;32m---> 81\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_y\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_x\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_y\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.pyenv\\mcmls\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:112\u001B[0m, in \u001B[0;36mIterator.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    109\u001B[0m     index_array \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex_generator)\n\u001B[0;32m    110\u001B[0m \u001B[38;5;66;03m# The transformation of images is not under thread lock\u001B[39;00m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;66;03m# so it can be done in parallel\u001B[39;00m\n\u001B[1;32m--> 112\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_batches_of_transformed_samples\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex_array\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.pyenv\\mcmls\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:313\u001B[0m, in \u001B[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001B[1;34m(self, index_array)\u001B[0m\n\u001B[0;32m    311\u001B[0m filepaths \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilepaths\n\u001B[0;32m    312\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(index_array):\n\u001B[1;32m--> 313\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43mimage_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_img\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilepaths\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolor_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolor_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_aspect_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeep_aspect_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    319\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    320\u001B[0m     x \u001B[38;5;241m=\u001B[39m image_utils\u001B[38;5;241m.\u001B[39mimg_to_array(img, data_format\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_format)\n\u001B[0;32m    321\u001B[0m     \u001B[38;5;66;03m# Pillow images should be closed after `load_img`,\u001B[39;00m\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;66;03m# but not PIL images.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.pyenv\\mcmls\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py:236\u001B[0m, in \u001B[0;36mload_img\u001B[1;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001B[0m\n\u001B[0;32m    234\u001B[0m         path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(path\u001B[38;5;241m.\u001B[39mresolve())\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m--> 236\u001B[0m         img \u001B[38;5;241m=\u001B[39m pil_image\u001B[38;5;241m.\u001B[39mopen(io\u001B[38;5;241m.\u001B[39mBytesIO(\u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m))\n\u001B[0;32m    237\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    238\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    239\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpath should be path-like or io.BytesIO, not \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    240\u001B[0m     )\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Train and evaluate all models\n",
    "pipeline.evaluate_all_models()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-14T16:10:21.319617700Z",
     "start_time": "2025-02-14T16:10:00.009329Z"
    }
   },
   "id": "eaf142723a885ba4",
   "execution_count": 131
  },
  {
   "cell_type": "markdown",
   "source": [
    "We save info on the disk"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fa22b5bbcdc973f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save results to disk\n",
    "pipeline.save_results()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-14T15:59:09.358056500Z"
    }
   },
   "id": "e11012c62f025bd8"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "32970cf4b31c058b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-14T15:59:09.360051300Z"
    }
   },
   "id": "e533cf6dc2cef7c"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "77d1f820a0cdde28"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Compare models for a specific dataset\n",
    "for d in loader.list_datasets():\n",
    "    pipeline.compare_models(d)\n",
    "\n",
    "# Compare datasets for a specific model\n",
    "for model in pipeline.list_models():\n",
    "    pipeline.compare_datasets(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-14T15:59:09.363055200Z"
    }
   },
   "id": "d2dc14f3404fdd5e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
